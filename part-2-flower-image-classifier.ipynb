{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# going modular: adapting the code that we have written in Kaggle notebooks so far to be used in python scripts\n# the directory structure will be discussed further down the line\n\n# Our goal is to train pytorch model using a single line in CMD/Terminal for e.g.:\n# python train.py --model Flower Image Classifier --batch_size 32 --lr 0.001 --num_epochs 2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-03T10:56:14.102091Z","iopub.execute_input":"2024-10-03T10:56:14.102711Z","iopub.status.idle":"2024-10-03T10:56:14.107436Z","shell.execute_reply.started":"2024-10-03T10:56:14.102656Z","shell.execute_reply":"2024-10-03T10:56:14.106581Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# creating a directory for going modular\n\n# necessary imports\nfrom pathlib import Path\n\n# using Path\nGOING_MODULAR = Path(\"./going_modular\")\n\n# checking if directory already exists\nif GOING_MODULAR.is_dir():\n  print(f\"{GOING_MODULAR} directory already exists...\")\nelse:\n  print(f\"{GOING_MODULAR} directory does not exist, creating...\")\n  GOING_MODULAR.mkdir(parents=True, exist_ok=True)\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:39:55.372803Z","iopub.execute_input":"2024-10-05T06:39:55.373677Z","iopub.status.idle":"2024-10-05T06:39:55.407125Z","shell.execute_reply.started":"2024-10-05T06:39:55.373636Z","shell.execute_reply":"2024-10-05T06:39:55.406164Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"going_modular directory does not exist, creating...\n","output_type":"stream"}]},{"cell_type":"code","source":"# installing torchmetrics since it is needed later\nimport pkgutil\n\nif pkgutil.find_loader('torchmetrics') is not None:\n    print(\"Package is installed\")\nelse:\n    print(\"Package is not installed, installing...\")\n    print()\n    !pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:40:00.271205Z","iopub.execute_input":"2024-10-05T06:40:00.271758Z","iopub.status.idle":"2024-10-05T06:40:00.281768Z","shell.execute_reply.started":"2024-10-05T06:40:00.271702Z","shell.execute_reply":"2024-10-05T06:40:00.280394Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Package is installed\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download the dataset\n# This cell has to run only once. \n# NO need to run every time you arrive on this notebook. \n\nimport requests\nimport tarfile\nimport os\nimport shutil\n\n# Define the URL and folder paths\nurl = \"https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\"\nfolder_name = \"flowers\"\nfile_name = \"flower_data.tar.gz\"\nfile_path = os.path.join(folder_name, file_name)\n\n# Remove the folder or symbolic link if it already exists (equivalent to `rm -rf flowers`)\ntry:\n    if os.path.islink(folder_name) or os.path.isfile(folder_name):\n        os.remove(folder_name)  # Remove the symbolic link or file\n    elif os.path.isdir(folder_name):\n        shutil.rmtree(folder_name)  # Remove the directory\n    print(f\"Removed existing {folder_name} folder/file/soft link, if any.\")\nexcept FileNotFoundError:\n    pass  # If the file or directory does not exist, do nothing\n\n# Create the folder\nos.makedirs(folder_name)\nprint(f\"Created folder: {folder_name}\")\n\n# Download the file\nresponse = requests.get(url, stream=True)\n\n# Save the file in the 'flowers' folder\nwith open('flower_data.tar.gz', \"wb\") as file:\n    for chunk in response.iter_content(chunk_size=1024):\n        if chunk:\n            file.write(chunk)\n\nprint(f\"Downloaded {file_name} to {folder_name}\")\n\n# Extract the file in the 'flowers' folder\nif file_path.endswith(\"tar.gz\"):\n    with tarfile.open('flower_data.tar.gz', \"r:gz\") as tar:\n        tar.extractall(path=folder_name)\n        print(f\"Extracted {file_name} to {folder_name}\")\n\n# Clean up by removing the tar.gz file after extraction\nos.remove('flower_data.tar.gz')\nprint(f\"Removed the downloaded tar.gz file: {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:40:09.007041Z","iopub.execute_input":"2024-10-05T06:40:09.007450Z","iopub.status.idle":"2024-10-05T06:40:24.009420Z","shell.execute_reply.started":"2024-10-05T06:40:09.007412Z","shell.execute_reply":"2024-10-05T06:40:24.008306Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Removed existing flowers folder/file/soft link, if any.\nCreated folder: flowers\nDownloaded flower_data.tar.gz to flowers\nExtracted flower_data.tar.gz to flowers\nRemoved the downloaded tar.gz file: flowers/flower_data.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile going_modular/data_acquire.py\n\"\"\"Module to download data in PyTorch standard image classification format.\n\nUsed for setting up data directories for downlaoding data as per\nthe directory structure. Contains function 'data_download' that takes\ninput from user for where to download the data and returns\n\"TRAIN_PATH\" and \"TEST_PATH\".\n\nTypical usage example:\n  from going_modular.data_acquire import data_download\n  TRAIN_PATH, TEST_PATH = data_download(path=USER_GIVEN_PATH)\n\"\"\"\n\n# necessary imports to download and load the dataset\nimport requests\nimport zipfile\nimport os\nfrom pathlib import Path\n\n# Define the URL and folder paths\nurl = \"https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\"\nfolder_name = \"flowers\"\nfile_name = \"flower_data.tar.gz\"\nfile_path = os.path.join(folder_name, file_name)\n\ndef data_download(path: str = 'file_path'):\n    \"\"\"Downloads subset of FOOD 101 at location defined by <path> parameter.\n\n    Args:\n        path: A string defining the path to the download location.\n          By default <path> is set to a string: 'vision_datasets'.\n\n    Returns:\n        A tuple of pathlib.PosixPath objects defining the training and\n        test set locations.\n\n        (TRAIN_PATH, TEST_PATH)\n    \"\"\"\n\n    # defining the location\n    FLOWER_DATASETS = Path(f\"./{path}\")\n    #FLOWER_DATASET \n\n    # if the path does not exist, download and prepare dataset\n    if FLOWER_DATASETS.is_dir():\n        print(f\"{FLOWER_DATASETS} directory already exists...\")\n    else:\n        print(f\"{FLOWER_DATASETS} directory does not exist, creating...\")\n        FLOWER_DATASETS.mkdir(parents=True, exist_ok=True)\n\n    # download flower dataset\n    with open('flower_data.tar.gz', \"wb\") as f:\n        request = requests.get(\"https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\")\n        print(\"Downloading flower images\")\n        f.write(request.content)\n\n    # unzipping flower dataset\n    #with zipfile.ZipFile('flower_data.tar.gz', 'r') as zip_ref:\n        #print(\"Unzipping flower dataset...\")\n        #zip_ref.extractall(FLOWER_DATASETS)\n\n    # removing the downloaded .zip\n    #os.remove('flowers/flower_data.tar.gz'.zip)\n\n    # setup train and test paths\n    TRAIN_PATH = FLOWER_DATASETS / \"train\"\n    TEST_PATH = FLOWER_DATASETS / \"test\"\n\n    # returning TRAIN_PATH and TEST_PATH\n    return TRAIN_PATH, TEST_PATH\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:40:41.667540Z","iopub.execute_input":"2024-10-05T06:40:41.668353Z","iopub.status.idle":"2024-10-05T06:40:41.676912Z","shell.execute_reply.started":"2024-10-05T06:40:41.668297Z","shell.execute_reply":"2024-10-05T06:40:41.675828Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Writing going_modular/data_acquire.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile going_modular/data_preprocess.py\n\"\"\"Module to preprocess datasets and convert to PyTorch datasets + dataloaders.\n\nFor preprocessing the downloaded dataset as required and turning it to PyTorch\ncompatible 'torchvision.datasets.ImageFolder' and further using this dataset to\nbuild dataloaders using 'torch.utils.data.DataLoader'.\n\nTypical usage example:\n  from going_modular.data_preprocess import data_setup\n  trainloader, testloader, classes, class_to_idx = data_setup(\n                                    train_path=PATH_TO_TRAIN_DATA,\n                                    test_path=PATH_TO_TEST_DATA,\n                                    data_transform=SOME_TRANSFORM)\n\"\"\"\n\n\n# necessary imports\nimport os\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# setting number of workers for data laoding\nNUM_WORKERS = os.cpu_count()\n\n# function to return iterables over the train and test datasets\ndef data_setup(train_path: str,\n               test_path: str,\n               data_transform: transforms.Compose,\n               batch_size: int = 32,\n               shuffle: bool = True):\n    \"\"\"For making datasets and their corresponding dataloaders.\n\n    Args:\n       train_path: A string defining the path to the training dataset location.\n       test_path: A string defining the path to the testing dataset location.\n       data_transform: An instance of transforms.Compose.\n       batch_size: An integer defining the batch size used (default: int '32').\n    shuffle: Bool value for whether to shuffle training dataset (default: True)\n\n   Returns:\n       A tuple of an instance each of 'torch.utils.data.DataLoader' for\n       train and test sets, list of classes in the dataset,\n       dict mapping a class to its corresponding numerical label.\n\n    (trainloader, testloader, classes, class_to_idx)\n  \"\"\"\n\n    # loading datasets\n    data_dir = 'flowers'\n    train_dir = data_dir + '/train'\n    test_dir = data_dir + '/test'\n    train_set = datasets.ImageFolder(data_dir + '/train', transform=data_transform)\n    test_set = datasets.ImageFolder(data_dir + '/test', transform=data_transform)\n\n    # making dataloaders from datasets\n    trainloader = torch.utils.data.DataLoader(train_path, batch_size=32, shuffle=True)\n    testloader = torch.utils.data.DataLoader(test_path, batch_size=32, shuffle=True)\n\n    # defining class list and class to label dictionary\n    classes = train_set.classes\n    class_to_idx = train_set.class_to_idx\n\n    # returning dataloaders, classes, class_to_idx\n    return trainloader, testloader, classes, class_to_idx\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:41:00.530670Z","iopub.execute_input":"2024-10-05T06:41:00.531407Z","iopub.status.idle":"2024-10-05T06:41:00.540260Z","shell.execute_reply.started":"2024-10-05T06:41:00.531363Z","shell.execute_reply":"2024-10-05T06:41:00.539047Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Writing going_modular/data_preprocess.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile going_modular/model_builder.py\n\"\"\"Module to define PyTorch model class and return its instance.\n\nVGG16 class inherits from 'nn.Module' in order to create\na PyTorch module. '__init__' method of the class has parameters to take\nthe number of kernels per layer <num_hidden_units> (default: int '10')\nand number of classes for the classification problem\n<num_classes> (default: int '10').\n\nTypical usage example:\n  import torch\n  from going_modular.model_builder import TinyVGGCNNExplainer\n  model = VGG16(nn.Module)\n  model.to('cuda' if torch.cuda.is_available() else 'cpu')\n\"\"\"\n\n# necessary imports\nimport torch\nimport torch.nn as nn\n\n# creating VGG16 for modelling the data\n\nclass VGG16(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG16, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        \n        \n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*256, 25088),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(25088, 25088),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(25088, num_classes))\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:41:08.598382Z","iopub.execute_input":"2024-10-05T06:41:08.599146Z","iopub.status.idle":"2024-10-05T06:41:08.607669Z","shell.execute_reply.started":"2024-10-05T06:41:08.599102Z","shell.execute_reply":"2024-10-05T06:41:08.606549Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Writing going_modular/model_builder.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile going_modular/engine.py\n# Imports here\n#%matplotlib inline\n#%config InlineBackend.figure_format = 'retina'\n\nimport torchvision\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport torch\nfrom collections import OrderedDict\n\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\n\nepochs = 3\nsteps = 0\nrunning_loss = 0\nprint_every = 5\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n        steps += 1\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            valid_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in validloader:\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    \n                    valid_loss += batch_loss.item()\n                    \n                    # Calculate accuracy\n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                    \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n                  f\"Validation loss: {valid_loss/len(validloader):.3f}.. \"\n                  f\"Validation accuracy: {accuracy/len(validloader):.3f}\")\n            running_loss = 0\n            model.train()\n            \n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T06:53:43.311638Z","iopub.execute_input":"2024-10-05T06:53:43.312066Z","iopub.status.idle":"2024-10-05T06:53:43.322140Z","shell.execute_reply.started":"2024-10-05T06:53:43.312028Z","shell.execute_reply":"2024-10-05T06:53:43.320926Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Writing going_modular/engine.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile train.py\n\"\"\"Script to initiate the training from terminal.\n\nThis script connects all the modules in 'going_modular'. Building the complete\ntraining pipeline + saving the trained model to './saved_models' directory.\n\nTypical usage example (from terminal):\n  !python train.py --batch_size 16 --num_hidden_units 32 --learning_rate 0.01 --epochs 3\n\"\"\"\n\n# necessary imports\nimport torch\nimport argparse\nfrom torchvision import transforms\nfrom going_modular.data_acquire import data_download\nfrom going_modular.data_preprocess import data_setup\nfrom going_modular.model_builder import TinyVGGCNNExplainer\nfrom going_modular.engine import metrics, optim_utils, training_step, testing_step, training_eval_loop, save_model\n\n# setting up the device to use\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# parsing arguments from terminal/CMD\nap = argparse.ArgumentParser()\nap.add_argument(\"-bs\", \"--batch_size\", type=int, default=32,\n                help=\"batch size to be used\")\nap.add_argument(\"-nh\", \"--num_hidden_units\", type=int, default=10,\n                help=\"number of hidden units for TinyVGG architecture\")\nap.add_argument(\"-lr\", \"--learning_rate\", type=float, default=0.001,\n                help=\"learning rate to use with the optimizer\")\nap.add_argument(\"-e\", \"--epochs\", type=int, default=5,\n                help=\"number of epochs to train the model for\")\nargs = vars(ap.parse_args())\n\n# setting up hyperparameters\nBATCH_SIZE = args[\"batch_size\"]\nNUM_HIDDEN_UNITS = args[\"num_hidden_units\"]\nLEARNING_RATE = args[\"learning_rate\"]\nEPOCHS = args[\"epochs\"]\n\n# setting up data transformation\ndataset_transform = transforms.Compose([transforms.Resize(size=(64,64)),\n                                        transforms.ToTensor()])\n\n# downloading data, setting up datasets and dataloaders\nTRAIN_PATH, TEST_PATH = data_download()\nprint() # for better output readability\ntrainloader, testloader, classes, class_to_idx = data_setup(\n                                              train_path=str(TRAIN_PATH),\n                                              test_path=str(TEST_PATH),\n                                              data_transform=dataset_transform,\n                                              batch_size=BATCH_SIZE)\n\n# setting up model\nnum_classes = 100\nnum_epochs = 20\nbatch_size = 16\nlearning_rate = 0.001\n\nmodel = VGG16(num_classes).to(device)\n\n\n# Loss and optimizer\ncriterion = nn.NLLLoss ()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n\n\n# Train the model\ntotal_step = len(train_loader)\n\nmodel.to(device)\n\n# setting up metrics, loss function and optimizer\ntrain_eval_metrics = metrics(device)\ncriterion, optimizer = optim_utils(model, LEARNING_RATE)\nprint() # for better output readability\n\n# starting training\nresults_dict = training_eval_loop(EPOCHS,\n                                  model,\n                                  training_step,\n                                  testing_step,\n                                  trainloader,\n                                  testloader,\n                                  criterion,\n                                  train_eval_metrics[0],\n                                  train_eval_metrics[1],\n                                  train_eval_metrics[2],\n                                  train_eval_metrics[3],\n                                  optimizer,\n                                  device)\nprint() # for better output readability\n\n# printing results of the trained model\nprint(f\"training loss: {results_dict['train_loss'][-1]:.3f} | training acc: {results_dict['train_acc'][-1]:.3f} | training f1-score: {results_dict['train_f1'][-1]:.3f}\")\nprint(f\"testing loss: {results_dict['test_loss'][-1]:.3f} | testing acc: {results_dict['test_acc'][-1]:.3f} | testing f1-score: {results_dict['test_f1'][-1]:.3f}\")\nprint() # for better output readability\n\n# saving model\nsave_model(model)\nprint() # for better output readability","metadata":{"execution":{"iopub.status.busy":"2024-10-05T07:16:00.443509Z","iopub.execute_input":"2024-10-05T07:16:00.443913Z","iopub.status.idle":"2024-10-05T07:16:00.455637Z","shell.execute_reply.started":"2024-10-05T07:16:00.443875Z","shell.execute_reply":"2024-10-05T07:16:00.454464Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Writing train.py\n","output_type":"stream"}]},{"cell_type":"code","source":"# executing the script\n!python train.py","metadata":{"execution":{"iopub.status.busy":"2024-10-05T00:06:40.483158Z","iopub.execute_input":"2024-10-05T00:06:40.483593Z","iopub.status.idle":"2024-10-05T00:07:13.370538Z","shell.execute_reply.started":"2024-10-05T00:06:40.483551Z","shell.execute_reply":"2024-10-05T00:07:13.368847Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"file_path directory already exists...\nDownloading flower images\n\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nTraceback (most recent call last):\n  File \"/kaggle/working/train.py\", line 82, in <module>\n    for inputs, labels in trainloader:\nValueError: too many values to unpack (expected 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}